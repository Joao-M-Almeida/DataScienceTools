{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Imports of all necessary Python Packages\n",
    "import sklearn as skl\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "#Decomposition\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "#Classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import NuSVC\n",
    "\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "#Evaluation\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Here import the data to classify\n",
    "data = np.random.rand(100,5)\n",
    "labels = np.random.randint(2,size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Extraction\n",
    "pca = PCA(n_components = 2)\n",
    "data_decomposed = pca.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Generate a Few of the most comon Scikit-Learn Classifiers\n",
    "#SVM\n",
    "classfSVM = SVC(C=1, kernel='rbf', gamma='auto', tol=1e-3)\n",
    "#SVM with control of the %(nu) of support vectors \n",
    "classfNuSVM = NuSVC(nu=0.5, kernel='rbf', gamma='auto', tol=1e-3)\n",
    "#LDA\n",
    "classfLDA = LinearDiscriminantAnalysis()\n",
    "#QDA\n",
    "classfQDA = QuadraticDiscriminantAnalysis()\n",
    "#KNN\n",
    "classfKNN = KNeighborsClassifier(n_neighbors=3, n_jobs=-1)\n",
    "#DecisionTree\n",
    "classfDecisionTree = DecisionTreeClassifier()\n",
    "#AdaBoost\n",
    "classfAdaBoost = AdaBoostClassifier(base_estimator=None, learning_rate=1, n_estimators=50)\n",
    "#RandomForest\n",
    "classfRandForest = RandomForestClassifier(n_estimators=10, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test a voting Classifier with the best performing ones.\n",
    "estimators = [('lda', LinearDiscriminantAnalysis()),  ('logReg', LogisticRegressionCV()),\n",
    "              ('adaB', AdaBoostClassifier(base_estimator=None, learning_rate=1, n_estimators=50))]\n",
    "classfVC = VotingClassifier(estimators= estimators, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Test classifier on all data or preferably on a Test set:\n",
    "#DON'T trust these results, there is an high chance of overfitting\n",
    "#Use ONLY to get a feel of the time Cross-Validation will take\n",
    "\n",
    "classf = classfVC\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data, labels, test_size=0.20, random_state=42)\n",
    "\n",
    "t0 = time()\n",
    "classf.fit(train_data,train_labels)\n",
    "print \"Score of Classifier: \" + str(classf.score(test_data,test_labels))\n",
    "print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Analyze Confusion Matrix\n",
    "true_labels = labels\n",
    "test_data = data\n",
    "classf = classfSVM\n",
    "predicted_labels = classf.predict(test_data)\n",
    "confusion_matrix(true_labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select parameters to use in Cross-Validation\n",
    "classf_cv = classfVC\n",
    "data_cv = data_decomposed\n",
    "N_CV = 10\n",
    "\n",
    "# Cross Validation\n",
    "t0 = time()\n",
    "scores = cross_validation.cross_val_score(classf_cv,data_cv,labels, n_jobs=-1, cv = N_CV)\n",
    "print \"Scores: \"\n",
    "for i,score in enumerate(scores):\n",
    "    print '\\t' + str(i) + ':\\t' + str(score) \n",
    "print(\"Accuracy: %0.3f (+/- %0.3f)\" % (scores.mean(), scores.std() * 2))\n",
    "print(\"\\nCross val done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test differente classifiers:\n",
    "\n",
    "classf_lst = [classfLDA, classfQDA, classfAdaBoost, classfSVM]\n",
    "\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(data_decomposed,\n",
    "                                                                    labels, test_size=0.20, random_state=42)\n",
    "for classf in classf_lst:\n",
    "    print classf\n",
    "    t0 = time()\n",
    "    classf.fit(train_data,train_labels)\n",
    "    print \"Score of Classifier: \" + str(classf.score(test_data,test_labels))\n",
    "    print(\"done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fine Tune with Grid-Search\n",
    "\n",
    "estimators = [('lda', LinearDiscriminantAnalysis()),  ('logReg', LogisticRegressionCV()),\n",
    "              ('adaB', AdaBoostClassifier(base_estimator=None, learning_rate=1, n_estimators=50))]\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('pca',PCA()),\n",
    "    ('VC', VotingClassifier(estimators= estimators, voting='hard'))\n",
    "])\n",
    "\n",
    "# Fine tune parameters using exaustive GridSearch:\n",
    "\n",
    "parameters = {\n",
    "    'pca__n_components': (2,3,),\n",
    "    'VC__adaB__n_estimators': (40,50,80)\n",
    "    \n",
    "    }\n",
    "    \n",
    "grid_search = GridSearchCV(pipeline, parameters,  verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t0 = time()\n",
    "grid_search.fit(data, labels)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
